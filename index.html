<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Feature-Conditioned Cascaded Video Diffusion Models for Precise Echocardiogram Synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>WAV2UIT: AN AUDIO-TEXTUAL DIFFUSION MODEL FOR TONGUE ULTRASOUND IMAGE GENERATION</title>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
  <script src="https://kit.fontawesome.com/93a5d09ba9.js" crossorigin="anonymous"></script>
</head>

<body>

  <!-- Title section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ATDM4UTI: AN AUDIO-TEXTUAL DIFFUSION MODEL FOR TONGUE ULTRASOUND IMAGE GENERATION</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Yudong Yang</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="#">Rongfeng Su</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="#">Nan Yan</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="#">Lan wang</a><sup>1,2</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>UKRI CDT in AI for Healthcare, Imperial College London, London,
                UK,</span><br>
              <span class="author-block"><sup>2</sup>Department of Computing, Imperial College London, London,
                UK,</span><br>
              <span class="author-block"><sup>3</sup>Department of Brain Sciences and Data Science Institute, Imperial
                College London, London, UK,</span><br>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href=""
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href=""
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract. -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This paper investigates the problem of acoustic-to-articulatory (AAI) for Ultrasound Tongue Image (UTI) generation.
              The key issues associated with current UTI based AAI methods are lacking of using universal information of tongue
              motion across different speakers, and limited abilities for modelling the long-range temporal dependencies across
              multiple consecutive pronunciations. To address these issues, this paper proposes an Audio-Textual Diffusion Model
              for UTI generation (ATDM4UTI). The proposed ATDM4UTI model consist of two modules: the speech-text encoding module
              and the audio-textual conditioned cascaded video diffusion generation module. The fist module is used to obtain
              detailed tongue movement information of individual speaker from speech inputs, and obtain the universal tongue
              movement information across different speakers from the ASR transcription. The second module based on the cascaded
              diffusion framework is used to capture the long-term dependencies across multiple consecutive pronunciations by
              step-by-step denoising sampling strategy. Experimental results on a Mandarin ultrasound-speech dataset showed that
              the proposed ATDM4UTI system can generate high-quality UTIs with clear tongue contour, which plays an important
              role in speech recognition and medical analysis. Compared to the state-of-the-art DNN based UTI-AAI system, the
              ATDM4UTI system achieved a LPIPS improvement of 67.95% relative and a FID improvement of 91.42% relative,
              respectively.


            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Video demo -->
  <section class="section">
    <div class="container content">
      <div class="columns is-centered has-text-centered">
        <div class="column">
      <!-- <div class="columns is-centered has-text-centered"> -->
          <h2 class="title is-3 is-centered"> This is  real and fake Ultrasound tongue imaging
          </h2>
          <p>Hover a video to see whether it's an original sample or a generated sample.</p>

          <div id="gif-mosaic">
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/original/speaker00013_M_s1_stn00031.gif?random=123" width="224" loop autoplay>
                <div class="caption">
                  <div>Original</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/original/speaker00013_M_s1_stn00062.gif" width="224">
                <div class="caption">
                  <div>Original</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/original/speaker00016_F_s1_stn00035.gif" width="224">
                <div class="caption">
                  <div>Original</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/original/speaker00016_F_s1_stn00035.gif" width="224">
                <div class="caption">
                  <div>Original</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/original/speaker00013_M_s1_stn00004.gif" width="224">
                <div class="caption">
                  <div>Original</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/original/speaker00012_M_s1_stn00089.gif" width="224">
                <div class="caption">
                  <div>Original</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+a/gif_output_speaker00013_M_s1_stn00031_sp.gif" width="224">
                <div class="caption">
                  <div>A4U+A</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+a/gif_output_speaker00013_M_s1_stn00062_sp.gif" width="224">
                <div class="caption">
                  <div>A4U+A</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+a/gif_output_speaker00016_F_s1_stn00035_sp.gif" width="224">
                <div class="caption">
                  <div>A4U+A</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+a/gif_output_speaker00016_F_s1_stn00035_sp.gif" width="224">
                <div class="caption">
                  <div>A4U+A</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+a/gif_output_speaker00016_F_s1_stn00035_sp.gif" width="224">
                <div class="caption">
                  <div>A4U+A</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+a/gif_output_speaker00016_F_s1_stn00035_sp.gif" width="224">
                <div class="caption">
                  <div>A4U+A</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+at/gif_output_speaker00013_M_s1_stn00031.gif" width="224">
                <div class="caption">
                  <div>A4U+AT</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+at/gif_output_speaker00013_M_s1_stn00062.gif" width="224">
                <div class="caption">
                  <div>A4U+AT</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+at/gif_output_speaker00014_M_s1_stn00064.gif" width="224">
                <div class="caption">
                  <div>A4U+AT</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+at/gif_output_speaker00016_F_s1_stn00035.gif" width="224">
                <div class="caption">
                  <div>A4U+AT</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+at/gif_output_speaker00020_F_s1_stn00123.gif" width="224">
                <div class="caption">
                  <div>A4U+AT</div>
                </div>
              </div>
            </div>
            <div class="video_wrapper">
              <div class="video_container">
                <img src="pool/a4u+at/gif_output_speaker00014_M_s1_stn00064.gif" width="224">
                <div class="caption">
                  <div>A4U+AT</div>
                </div>
              </div>
            </div>
          </div>
          <div><span id="score">Score: 0/0 (0%)</span></div>
        </div>
      </div>
    </div>
  </section>

  <!-- diffusion demo huggingface -->
  <!-- <section class="section" id="hfdemo">
    <div class="container is-max-desktop content">
      <div class="columns is-centered has-text-centered">
        <div class="column is-max-desktop">
          <h2 class="title is-3">Diffusion model inference</h2>
          <iframe src="https://anon-sgxt-echocardiogram-video-diffusion.hf.space"
            frameborder="0"
            width="1280"
            height="800">
          </iframe>
        </div>
      </div>
    </div>
  </section> -->



  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @misc{reynaud2023featureconditioned,
          title={Feature-Conditioned Cascaded Video Diffusion Models for Precise Echocardiogram Synthesis},
          author={Hadrien Reynaud and Mengyun Qiao and Mischa Dombrowski and Thomas Day and Reza Razavi and Alberto Gomez and Paul Leeson and Bernhard Kainz},
          year={2023},
          eprint={2303.12644},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
        }
    </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Website source code based on the source code of
              <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
<script>
  // 获取所有的视频容器元素
  const videoContainers = document.querySelectorAll('.video_container');

  // 遍历每个视频容器
  videoContainers.forEach((container) => {
    const img = container.querySelector('img'); // 获取容器内的GIF元素
    img.addEventListener('mouseover', () => {
      img.src = img.src + '?random=' + Math.random(); // 添加随机参数，强制重新加载GIF
    });
  });
</script>

</html>


